{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qnGlVVE3rtbJ"
   },
   "source": [
    "**Task 5**\n",
    "\n",
    "\n",
    "1.   Finding out most discussed 10 topics using LDA\n",
    "\n",
    "Aditional Steps\n",
    "\n",
    "1.   Finding out the performance of the generated LDA\n",
    "2.   FInding out best optimal number of topics for a better model\n",
    "3.   Analysis using pyLadvis\n",
    "\n",
    "\n",
    "Inputs for this task are files from the location data/Task 5/input\n",
    "These files are same as the files in the data/Task 1/Result (output from the task 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_bLGYVzx_Px7",
    "outputId": "c54f1952-d652-4fe0-81b6-44fafa89f53d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Sasini\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'use'])\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ITvvch5u_iFN",
    "outputId": "3d1b058c-d2d8-4507-9fff-e962d7c7a06f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sasini\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\past\\builtins\\misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 10 Topics obtained from the reviews of Emergency Plus.csv - Tf Corpus\n",
      "0::['life', 'save', 'much', 'locate', 'accident', 'apple_watch', 'able', 'review', 'test', 'quickly']\n",
      "1::['app', 'emergency', 'location', 'great', 'need', 'address', 'phone', 'gps', 'good', 'idea']\n",
      "2::['try', 'away', 'tell', 'area', 'however', 'correct', 'rural', 'name', 'live', 'family']\n",
      "3::['people', 'button', 'contact', 'map', 'share', 'mobile', 'alert', 'helpful', 'direct', 'maybe']\n",
      "4::['want', 'mean', 'far', 'kilometre', 'logo', 'perfectly', 'new', 'recent', 'hope_never', 'clear']\n",
      "5::['long', 'keep', 'actually', 'take', 'go', 'report', 'exact', 'small', 'old', 'seem']\n",
      "6::['also', 'read', 'make', 'see', 'download', 'screen', 'useful', 'well', 'information', 'turn']\n",
      "7::['work', 'update', 'fix', 'still', 'iphone', 'app', 'fire', 'phone', 'application', 'handy']\n",
      "8::['know', 'recommend', 'situation', 'dispatch', 'always', 'life_save', 'bad', 'due', 'often', 'highly']\n",
      "9::['time', 'home', 'open', 'crash', 'operator', 'word', 'accurate', 'thank', 'even', 'send']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from tabulate import tabulate\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as genismnvis  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "topicsname=[]\n",
    "num_topics =10\n",
    "bigramDataWords = []\n",
    "trigramDataWords = []\n",
    "EvaluationResults =[]\n",
    "appDetailInputsForLDA =[]\n",
    "ldaModelDetailsTfAppWise =[]\n",
    "ldaModelDetailsTfIdfAppWise =[]\n",
    "\n",
    "#function for preprocessing Data\n",
    "def PreProcessReviewData(reviewData):\n",
    "    for review in reviewData:\n",
    "        yield gensim.utils.simple_preprocess(str(review), deacc=True, min_len=2)  # deacc=True removes punctuations\n",
    "\n",
    "#function for removing stopwords\n",
    "def removeStopWords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "#function for bigram creation \n",
    "def make_bigrams(texts):\n",
    "    for doc in texts:\n",
    "        x = bigram_mod[doc]\n",
    "        bigramDataWords.append(x)\n",
    "    return bigramDataWords\n",
    "\n",
    "#function for trigram creation \n",
    "def make_trigrams(texts):\n",
    "    for doc in texts:\n",
    "        y = trigram_mod[bigram_mod[doc]]\n",
    "        trigramDataWords.append(y)\n",
    "    return trigramDataWords\n",
    "\n",
    "#function for lemmatization\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent))\n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n",
    "\n",
    "#function for training LDA model with Tf corpus\n",
    "def TrainLdaModelWithTf(corpus, id2word, topics = 10, passes= 10, iterations =50) :\n",
    "    ldaModel = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                            id2word=id2word,\n",
    "                                            num_topics=topics,\n",
    "                                            random_state=100,\n",
    "                                            update_every=1,\n",
    "                                            chunksize=100,\n",
    "                                            passes=passes,\n",
    "                                            alpha='auto',\n",
    "                                            per_word_topics=True,\n",
    "                                            iterations=iterations)\n",
    "    return ldaModel\n",
    "\n",
    "#function for training LDA model with TfIdf corpus\n",
    "def TrainLdaModelWithTfIdf(corpus, id2word, topics = 10, passes= 10, iterations =50) :\n",
    "    ldaModel = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                            id2word=id2word,\n",
    "                                            num_topics= topics,\n",
    "                                            random_state=100,\n",
    "                                            chunksize=100,\n",
    "                                            passes=passes,\n",
    "                                            per_word_topics=True,\n",
    "                                            iterations= iterations)\n",
    "    return ldaModel\n",
    "\n",
    "#function for evaluate LDA model\n",
    "def EvaluatePerformance(appName, corpus, ldaModel, corpusType):\n",
    "    results =[appName, corpusType]\n",
    "    perplexity = ldaModel.log_perplexity(corpus)\n",
    "\n",
    "    # Compute CV Coherence Score\n",
    "    cvCoherenceModel = CoherenceModel(model=ldaModel, texts=lemmatizedData, dictionary=id2word, coherence='c_v')\n",
    "    cvCoherence = cvCoherenceModel.get_coherence()\n",
    "\n",
    "    # Compute umass Coherence Score\n",
    "    uMassCoherenceModel = CoherenceModel(model=ldaModel, texts=lemmatizedData, dictionary=id2word, coherence='u_mass')\n",
    "    uMassCoherence = uMassCoherenceModel.get_coherence()\n",
    "\n",
    "    results.append(perplexity)\n",
    "    results.append(cvCoherence)\n",
    "    results.append(uMassCoherence)\n",
    "\n",
    "    return results\n",
    "\n",
    "#function for printing words in the topic\n",
    "def PrintTopicWords(wordSet):\n",
    "    topics_words = [(tp[0], [wd[0] for wd in tp[1]]) for tp in wordSet]\n",
    "    for topic,words in topics_words:\n",
    "        print(str(topic)+ \"::\"+ str(words))\n",
    "\n",
    "#function for plpting LDA model generated topics\n",
    "def PlottingResults(ldamodel, corpus, id2word):\n",
    "    pyLDAvis.enable_notebook()\n",
    "    vis = genismnvis.prepare(ldamodel, corpus, id2word)\n",
    "    return vis\n",
    "\n",
    "\n",
    "apps = ['Emergency Plus.csv', 'Red Cross First Aid.csv']\n",
    "\n",
    "for i in range(len(apps)) :\n",
    "    df = pd.read_csv('./data/Task 5/Input/'+apps[i])\n",
    "    reviewDataList = df['Review'].values.tolist()\n",
    "\n",
    "    #preprocessing using genism simple pre process\n",
    "    reviewDataWords = list(PreProcessReviewData(reviewDataList))\n",
    "\n",
    "    #stopword removal using nltk stop words\n",
    "    reviewDataWordsWithoutStopWords = removeStopWords(reviewDataWords)\n",
    "\n",
    "    # bigram trigram models\n",
    "    bigram = gensim.models.Phrases(reviewDataWords, min_count=5, threshold=100)\n",
    "    trigram = gensim.models.Phrases(bigram[reviewDataWords], threshold=100)\n",
    "\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "  \n",
    "    #creating bigram trigram models from the data set\n",
    "    dataWordsWithbigrams = make_bigrams(reviewDataWordsWithoutStopWords)\n",
    "    dataWordsWithTrigrams = make_trigrams(dataWordsWithbigrams)\n",
    "\n",
    "    #lemmatizing data set\n",
    "    lemmatizedData = lemmatization(dataWordsWithTrigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "  \n",
    "    #create dictionary as the input for lda model\n",
    "    id2word = corpora.Dictionary(lemmatizedData)\n",
    "\n",
    "    # Create Corpus\n",
    "    texts = lemmatizedData\n",
    "\n",
    "    # create corpus with Term Document Frequency\n",
    "    corpusTf = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "    #create corpus with tf-idf\n",
    "    tfidf = gensim.models.TfidfModel(corpusTf)\n",
    "    corpusTfidf = tfidf[corpusTf]\n",
    "  \n",
    "    #store details in dictionary for use later for evaluation\n",
    "    dictionary = {'appName':apps[i],'id2word':id2word, 'lemmatized': lemmatizedData, 'tf' : corpusTf, 'tfIdf': corpusTfidf }\n",
    "    appDetailInputsForLDA.append(dictionary)\n",
    "\n",
    "    ldaModelTfDetails =[]\n",
    "    ldaModelTfIdfDetails =[]\n",
    "\n",
    "    ldaModelTf = TrainLdaModelWithTf(corpusTf, id2word)\n",
    "    ldaModelTfWords = ldaModelTf.show_topics(num_topics=10, num_words=10,formatted=False)\n",
    "    print(\"\\n 10 Topics obtained from the reviews of \"+apps[i]+ \" - Tf Corpus\")\n",
    "    PrintTopicWords(ldaModelTfWords)\n",
    "    #pprint(ldaModelTf.print_topics()) -print with probabilities\n",
    "    results = EvaluatePerformance(apps[i], corpusTf, ldaModelTf, corpusType = 'TF')\n",
    "    EvaluationResults.append(results)\n",
    "\n",
    "    #Store details to utilize when plotting graphs\n",
    "    ldaModelTfDetails.append(ldaModelTf)\n",
    "    ldaModelTfDetails.append(corpusTf)\n",
    "    ldaModelTfDetails.append(id2word)\n",
    "    ldaModelDetailsTfAppWise.append(ldaModelTfDetails)\n",
    "\n",
    "    ldaModelTfIdf = TrainLdaModelWithTfIdf(corpusTfidf, id2word)\n",
    "    ldaModelTIdffWords = ldaModelTfIdf.show_topics(num_topics=10, num_words=10,formatted=False)\n",
    "    print(\"\\n 10 Topics obtained from the reviews of \"+apps[i]+ \" - TfIdf Corpus\")\n",
    "    PrintTopicWords(ldaModelTIdffWords)\n",
    "    #pprint(ldaModelTfIdf.print_topics()) -print with probabilities\n",
    "    results = EvaluatePerformance(apps[i], corpusTfidf, ldaModelTfIdf, corpusType = 'TF-IDF')\n",
    "    EvaluationResults.append(results)\n",
    "  \n",
    "    #Store details to utilize when plotting graphs\n",
    "    ldaModelTfIdfDetails.append(ldaModelTfIdf)\n",
    "    ldaModelTfIdfDetails.append(corpusTfidf)\n",
    "    ldaModelTfIdfDetails.append(id2word)\n",
    "    ldaModelDetailsTfIdfAppWise.append(ldaModelTfIdfDetails)\n",
    "\n",
    "print (tabulate(EvaluationResults, headers=[\"App Name\", \"Corpus Type\" \"Perplexity\", \"Cv coherence score\", \"U mass Coherence score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "42V1KpDtKSh9"
   },
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model=gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, random_state=100,\n",
    "                                            update_every=1,\n",
    "                                            chunksize=100,\n",
    "                                            passes=10,\n",
    "                                            alpha='auto',\n",
    "                                            per_word_topics=True,\n",
    "                                            iterations=50)\n",
    "                                            \n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jSS5f_kCVVKY"
   },
   "outputs": [],
   "source": [
    "def PlotCoherenceValueAgainstNumofTopics(appName, model, coherence_values):\n",
    "    limit=40; start=2; step=6;\n",
    "    x = range(start, limit, step)\n",
    "    plt.plot(x, coherence_values)\n",
    "    plt.title(appName)\n",
    "    plt.xlabel(\"Num Topics\")\n",
    "    plt.ylabel(\"Coherence score \"+ model)\n",
    "    plt.legend((\"coherence_values\"), loc='best')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "QFlJjzZJKaCO",
    "outputId": "5a366c52-f948-4578-849d-24cdfd60b931"
   },
   "outputs": [],
   "source": [
    "#appDetailInputsForLDA containing details related to emergency app\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=appDetailInputsForLDA[0]['id2word'], corpus=appDetailInputsForLDA[0]['tf'], texts=appDetailInputsForLDA[0]['lemmatized'], start=2, limit=40, step=6)\n",
    "PlotCoherenceValueAgainstNumofTopics(\"Emergency Plus app\", \"tf model\", coherence_values)\n",
    "\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=appDetailInputsForLDA[0]['id2word'], corpus=appDetailInputsForLDA[0]['tfIdf'], texts=appDetailInputsForLDA[0]['lemmatized'], start=2, limit=40, step=6)\n",
    "PlotCoherenceValueAgainstNumofTopics(\"Emergency Plus app\", \"tf-idf model\", coherence_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "XXBmaoa7WuCC",
    "outputId": "7d0ee410-5fe9-4c86-9f3b-f4afd6663309"
   },
   "outputs": [],
   "source": [
    "#appDetailInputsForLDA containing details related to red cross first aid app\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=appDetailInputsForLDA[1]['id2word'], corpus=appDetailInputsForLDA[1]['tf'], texts=appDetailInputsForLDA[1]['lemmatized'], start=2, limit=40, step=6)\n",
    "PlotCoherenceValueAgainstNumofTopics(\"Red cross first aid app\", \"tf model\", coherence_values)\n",
    "\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=appDetailInputsForLDA[1]['id2word'], corpus=appDetailInputsForLDA[1]['tfIdf'], texts=appDetailInputsForLDA[1]['lemmatized'], start=2, limit=40, step=6)\n",
    "PlotCoherenceValueAgainstNumofTopics(\"ed cross first aid app\", \"tf-idf model\", coherence_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PHV132B4sfFr",
    "outputId": "07f75ad8-68a3-446b-f8c7-367ff3ec47a0"
   },
   "outputs": [],
   "source": [
    "# same process is rerunning just changing the num of topics to optimal number of topics.\n",
    "\n",
    "bigramDataWords = []\n",
    "trigramDataWords = []\n",
    "EvaluationResults =[]\n",
    "appDetailInputsForLDA =[]\n",
    "ldaModelDetailsTfAppWise =[]\n",
    "ldaModelDetailsTfIdfAppWise =[]\n",
    "\n",
    "\n",
    "apps = ['Emergency Plus.csv', 'Red Cross First Aid.csv']\n",
    "\n",
    "for i in range(len(apps)) :\n",
    "    if i== 0 :\n",
    "        numberOfTfTopics = 13\n",
    "        numberofTfIdfTopics = 8\n",
    "    else:\n",
    "        numberOfTfTopics = 14\n",
    "        numberofTfIdfTopics = 8\n",
    "\n",
    "    df = pd.read_csv('/content/'+apps[i])\n",
    "    reviewDataList = df['Review'].values.tolist()\n",
    "\n",
    "    #preprocessing using genism simple pre process\n",
    "    reviewDataWords = list(PreProcessReviewData(reviewDataList))\n",
    "\n",
    "    #stopword removal using nltk stop words\n",
    "    reviewDataWordsWithoutStopWords = removeStopWords(reviewDataWords)\n",
    "\n",
    "    # bigram trigram models\n",
    "    bigram = gensim.models.Phrases(reviewDataWords, min_count=5, threshold=100)\n",
    "    trigram = gensim.models.Phrases(bigram[reviewDataWords], threshold=100)\n",
    "\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "  \n",
    "    #creating bigram trigram models from the data set\n",
    "    dataWordsWithbigrams = make_bigrams(reviewDataWordsWithoutStopWords)\n",
    "    dataWordsWithTrigrams = make_trigrams(dataWordsWithbigrams)\n",
    "\n",
    "    #lemmatizing data set\n",
    "    lemmatizedData = lemmatization(dataWordsWithTrigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "  \n",
    "    #create dictionary as the input for lda model\n",
    "    id2word = corpora.Dictionary(lemmatizedData)\n",
    "\n",
    "    # Create Corpus\n",
    "    texts = lemmatizedData\n",
    "\n",
    "    # create corpus with Term Document Frequency\n",
    "    corpusTf = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "    #create corpus with tf-idf\n",
    "    tfidf = gensim.models.TfidfModel(corpusTf)\n",
    "    corpusTfidf = tfidf[corpusTf]\n",
    "  \n",
    "    #store details in dictionary for use later for evaluation\n",
    "    dictionary = {'appName':apps[i],'id2word':id2word, 'lemmatized': lemmatizedData, 'tf' : corpusTf, 'tfIdf': corpusTfidf }\n",
    "    appDetailInputsForLDA.append(dictionary)\n",
    "\n",
    "    ldaModelTfDetails =[]\n",
    "    ldaModelTfIdfDetails =[]\n",
    "\n",
    "    ldaModelTf = TrainLdaModelWithTf(corpusTf, id2word, numberOfTfTopics)\n",
    "    ldaModelTfWords = ldaModelTf.show_topics(num_topics=10, num_words=10,formatted=False)\n",
    "    print(\"\\n \")\n",
    "    print(numberOfTfTopics)\n",
    "    print(\" Topics obtained from the reviews of \"+apps[i]+ \" - Tf Corpus\")\n",
    "    PrintTopicWords(ldaModelTfWords)\n",
    "    #pprint(ldaModelTf.print_topics()) -print with probabilities\n",
    "    results = EvaluatePerformance(apps[i], corpusTf, ldaModelTf, corpusType = 'TF')\n",
    "    EvaluationResults.append(results)\n",
    "\n",
    "    #Store details to utilize when plotting graphs\n",
    "    ldaModelTfDetails.append(ldaModelTf)\n",
    "    ldaModelTfDetails.append(corpusTf)\n",
    "    ldaModelTfDetails.append(id2word)\n",
    "    ldaModelDetailsTfAppWise.append(ldaModelTfDetails)\n",
    "\n",
    "    ldaModelTfIdf = TrainLdaModelWithTfIdf(corpusTfidf, id2word, numberofTfIdfTopics)\n",
    "    ldaModelTIdffWords = ldaModelTfIdf.show_topics(num_topics=10, num_words=10,formatted=False)\n",
    "    print(\"\\n \")\n",
    "    print(numberofTfIdfTopics)\n",
    "    print(\" Topics obtained from the reviews of \"+apps[i]+ \" - TfIdf Corpus\")\n",
    "    PrintTopicWords(ldaModelTIdffWords)\n",
    "    #pprint(ldaModelTfIdf.print_topics()) -print with probabilities\n",
    "    results = EvaluatePerformance(apps[i], corpusTfidf, ldaModelTfIdf, corpusType = 'TF-IDF')\n",
    "    EvaluationResults.append(results)\n",
    "  \n",
    "    #Store details to utilize when plotting graphs\n",
    "    ldaModelTfIdfDetails.append(ldaModelTfIdf)\n",
    "    ldaModelTfIdfDetails.append(corpusTfidf)\n",
    "    ldaModelTfIdfDetails.append(id2word)\n",
    "    ldaModelDetailsTfIdfAppWise.append(ldaModelTfIdfDetails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "id": "NVs-JMyXzFIw",
    "outputId": "e69099b7-63df-46ce-bfa2-713239c996fe"
   },
   "outputs": [],
   "source": [
    "#plotting for emergency app tf corpus\n",
    "vis =PlottingResults(ldaModelDetailsTfAppWise[0][0], ldaModelDetailsTfAppWise[0][1], ldaModelDetailsTfAppWise[0][2])\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "id": "6-7rZ_NezScm",
    "outputId": "4d6e7d60-c967-4d85-8d74-4bb053fba20e"
   },
   "outputs": [],
   "source": [
    "#plotting for emergency app tf idf corpus\n",
    "vis =PlottingResults(ldaModelDetailsTfIdfAppWise[0][0], ldaModelDetailsTfIdfAppWise[0][1], ldaModelDetailsTfIdfAppWise[0][2])\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "id": "_gxfMrAKzWah",
    "outputId": "1e926372-6ba6-46e9-f364-5c003bd0e5a9"
   },
   "outputs": [],
   "source": [
    "#plotting for red cross app tf corpus\n",
    "vis =PlottingResults(ldaModelDetailsTfAppWise[1][0], ldaModelDetailsTfAppWise[1][1], ldaModelDetailsTfAppWise[1][2])\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "id": "FExqxqbt0cU2",
    "outputId": "1c867783-9bf7-49fe-e2e3-0272f05bdd86"
   },
   "outputs": [],
   "source": [
    "#plotting for red cross first aid app tf idf corpus\n",
    "vis =PlottingResults(ldaModelDetailsTfIdfAppWise[1][0], ldaModelDetailsTfIdfAppWise[1][1], ldaModelDetailsTfIdfAppWise[1][2])\n",
    "vis"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
